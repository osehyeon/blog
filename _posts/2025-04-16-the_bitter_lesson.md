---
layout: single
title:  "The Bitter Lesson"
categories: "일상"
toc: true
typora-root-url: .
---

Rich Sutton의 「The Bitter Lesson」 에 대해 다루고 있다. 

## The Bitter Lesson 

Rich Sutton

2019년 3월 13일

### AI 연구의 가장 큰 교훈 

70년간의 인공지능 연구에서 읽어낼 수 있는 가장 큰 교훈은, 계산을 활용하는 일반적인 방법들이 궁극적으로 가장 효과적이라는 것이며, 그 차이는 매우 크다는 것이다. 이러한 궁극적인 이유는 무어의 법칙, 또는 좀 더 일반화된 형태의 계산 단위당 비용이 지속적으로 지수적으로 감소한다는 사실에 있다.

대부분의 인공지능 연구는 마치 에이전트가 사용할 수 있는 계산량이 고정되어 있는 것처럼 수행되어 왔으며, 이 경우 성능을 향상시키는 유일한 방법 중 하나는 인간의 지식을 활용하는 것이다. 하지만 전형적인 연구 프로젝트 기간보다 약간 더 긴 시간 안에 훨씬 더 많은 계산량이 필연적으로 사용 가능해진다.

단기적인 차이점을 만들기 위한 향상을 추구하면서, 연구자들은 자신이 가진 도메인 지식을 활용하고자 하지만, 장기적으로는 계산을 활용하는 것만이 중요하다. 이 둘은 반드시 서로 상충하는 것은 아니지만, 실제로는 그렇게 작용하는 경우가 많다. 하나에 시간을 쓰면 다른 것에 시간을 쓸 수 없다. 연구자는 자신이 투자한 접근 방식에 심리적으로 얽매이게 된다. 그리고 인간 지식을 활용하는 접근은 계산을 활용하는 일반적인 방법과 결합하기 어려울 정도로 방법을 복잡하게 만드는 경향이 있다.

AI 연구자들이 이 쓴 교훈을 뒤늦게 깨달았던 많은 사례들이 있으며, 그 중 가장 주목할 만한 것들을 되짚어보는 것은 교육적으로 의미가 있다.

### 컴퓨터 체스: 단순한 탐색의 승리

컴퓨터 체스 분야에서는, 1997년 세계 챔피언 카스파로프를 이긴 방법이 대규모의 깊은 탐색에 기반한 것이었다. 당시 이 방식은 대부분의 컴퓨터 체스 연구자들에게 실망스럽게 여겨졌다. 그들은 체스의 특별한 구조에 대한 인간의 이해를 활용하는 방식들을 추구해 왔기 때문이다.

단순하고 탐색 기반의 접근이 특수 하드웨어 및 소프트웨어와 함께 훨씬 더 효과적인 것으로 드러나자, 인간 지식 기반의 체스 연구자들은 이를 좋게 받아들이지 않았다. 그들은 “무식한(brute force)” 탐색이 이번에는 승리했지만 그것은 일반적인 전략이 아니며, 어쨌든 사람이 체스를 두는 방식도 아니라고 말했다. 이 연구자들은 인간의 입력에 기반한 방식이 승리하길 원했고, 그렇지 못한 것에 실망했다.

### 컴퓨터 바둑: 자가 학습과 탐색의 전환

컴퓨터 바둑에서도 유사한 연구 진보의 양상이 나타났으며, 단지 20년 더 늦게 나타났을 뿐이다. 초기에는 인간 지식이나 게임의 특별한 특징을 활용해 탐색을 회피하려는 노력이 거대하게 이루어졌지만, 이러한 모든 노력은 결국 무의미하거나, 오히려 해가 되기까지 했으며, 탐색이 대규모로 효과적으로 적용되자 상황이 바뀌었다.

또한 자가 대국(self play)을 통한 가치 함수 학습 역시 중요했는데, 이는 다른 많은 게임들에서도, 심지어 체스에서도 마찬가지였으며, 1997년에 세계 챔피언을 이긴 프로그램에서는 학습이 큰 역할을 하진 않았지만 말이다.

자가 학습과 일반적인 학습은 탐색과 마찬가지로 대규모 계산을 활용할 수 있게 해준다. 탐색과 학습은 인공지능 연구에서 대규모 계산을 활용하기 위한 가장 중요한 두 종류의 기법이다.

컴퓨터 바둑에서도 컴퓨터 체스와 마찬가지로, 초기 연구자들의 노력은 인간의 이해를 활용하여 탐색을 줄이는 데 초점이 맞추어졌고, 훨씬 뒤에야 탐색과 학습을 수용함으로써 훨씬 더 큰 성공이 가능해졌다.

### 음성 인식: 통계적 접근의 승리

음성 인식 분야에서도 유사한 패턴이 있었다. 1970년대 DARPA가 주관한 초기 경연에서는 인간의 지식을 활용하는 여러 특수한 방법들, 즉 단어, 음소, 인간 성대의 구조 등에 대한 지식이 등장했으며, 반대편에는 통계적 성격이 강하고 훨씬 더 많은 계산을 필요로 하는 새로운 방식들이 있었는데, 이들은 은닉 마르코프 모델(HMM)에 기반한 방식이었다.

이 경우에도 통계적 방식이 인간 지식 기반의 방식들을 능가했다. 이것은 자연어처리 전체 분야에 주요한 변화를 불러왔으며, 수십 년에 걸쳐 점진적으로 일어났다. 통계와 계산이 이 분야를 지배하게 된 것이다.

최근 딥러닝의 부상은 이러한 일관된 방향성에서 가장 최근에 발생한 단계다. 딥러닝 방식은 인간 지식을 덜 활용하고, 훨씬 더 많은 계산과 대규모 훈련 데이터를 통해 음성 인식 시스템의 성능을 획기적으로 향상시켰다.

게임들에서처럼, 연구자들은 시스템이 자기 자신의 사고 방식처럼 작동하길 바랐고, 그런 지식을 시스템에 넣으려 했지만, 결과적으로 이는 궁극적으로 역효과를 낳았으며, 무어의 법칙에 따라 막대한 계산이 가능해지고, 그것을 잘 활용할 수 있는 방법이 나타났을 때, 연구자들의 시간은 큰 낭비로 귀결되었다.

### 컴퓨터 비전: 과거의 이론을 넘어

컴퓨터 비전에서도 비슷한 양상이 있었다. 초기의 방식들은 시각을 엣지를 찾는 것으로 보거나, 일반화된 실린더 형태, 혹은 SIFT 특징을 중심으로 구성했다. 하지만 오늘날에는 이러한 것들이 모두 폐기되었다.

현대의 딥러닝 신경망은 컨볼루션과 특정 종류의 불변성 개념만을 사용하며, 훨씬 더 나은 성능을 낸다.

### 반복되는 실수와 쓴 교훈

이것은 큰 교훈이다. 이 분야 전체가 아직 완전히 배우지 못했으며, 우리는 여전히 같은 종류의 실수를 반복하고 있다. 이를 인식하고 효과적으로 저항하려면, 이러한 실수들이 갖는 매력을 이해해야 한다.

우리는 다음과 같은 쓴 교훈을 배워야 한다.

- AI 연구자들은 종종 지식을 에이전트에 넣으려고 시도한다.
- 이는 단기적으로는 도움이 되고, 연구자 개인에게는 만족감을 준다.
- 하지만 장기적으로는 한계에 도달하고, 더 이상의 발전을 방해하게 된다.
- 그리고 결정적인 진보는 결국 탐색과 학습을 통한 계산의 확장이라는 반대 접근 방식에서 등장한다.

이러한 성공은 감정적으로 받아들이기 어려운 것이며, 인간 중심 접근법에 대한 애착으로 인해 완전히 받아들여지지 않는 경우도 많다.

### 진짜로 배워야 할 것들

이 쓴 교훈에서 배워야 할 첫 번째 일반적인 포인트는, 일반 목적의 방법들, 즉 계산량이 증가함에 따라 계속해서 성능이 확장될 수 있는 방법들의 강력함이다. 이와 같이 임의적으로라도 계속해서 확장 가능한 것으로 보이는 두 가지 방법은 탐색과 학습이다.

두 번째 포인트는, 마음의 실제 내용은 엄청나게, 되돌릴 수 없을 만큼 복잡하다는 것이다. 우리는 공간, 물체, 다중 에이전트, 또는 대칭성과 같은 마음의 내용을 단순하게 설명하려는 시도를 멈춰야 한다. 이러한 것들은 모두 임의적이고 본질적으로 복잡한 외부 세계의 일부이다. 이들은 시스템에 내장해야 할 것이 아니다. 그 복잡성은 끝이 없다.

우리가 내장해야 할 것은 이러한 임의적 복잡성을 찾아내고 포착할 수 있는 메타-방법들뿐이다. 이 방법들에 필수적인 것은 좋은 근사를 찾아낼 수 있는 능력이며, 그 탐색은 우리가 아닌 우리의 방법들이 해야 한다.

우리는 우리가 발견한 것을 포함한 AI 에이전트를 원해서는 안 된다. 우리는 우리가 발견하는 방식처럼 스스로 발견할 수 있는 AI를 원해야 한다. 우리의 발견을 시스템에 넣는 것은, 오히려 발견하는 과정이 어떻게 이루어지는지를 이해하는 데 장애가 될 뿐이다.

## Reference 

- [The Bitter Lesson](http://incompleteideas.net/IncIdeas/BitterLesson.html)

  